{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4837f0e6",
   "metadata": {},
   "source": [
    "# <font color=Blue>Databricks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5df038",
   "metadata": {},
   "source": [
    "- Azure Databricks is a popular cloud-based data analytics service offered by Microsoft Azure\n",
    "- It allows you to perform data analytics on huge amounts of data on Azure\n",
    "- Azure Databricks cluster uses Spark Standalone cluster\n",
    "- Control pane holds metadata information like, databricks web app, notebooks, jobs & queris, cluster manager\n",
    "- Compute pane holds data, Vnet, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ff6b49",
   "metadata": {},
   "source": [
    "![databricks](./Databricks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074cd556",
   "metadata": {},
   "source": [
    "## 1) Databricks Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48f771",
   "metadata": {},
   "source": [
    "* Cluster is a set of computation resources and configurations to run your workloads\n",
    "* There are 2 types of cluster\n",
    "     - All purpose Cluster\n",
    "     - Job Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098aed15",
   "metadata": {},
   "source": [
    "### 1.1) All Purpose Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a1985",
   "metadata": {},
   "source": [
    "* To interactively run the commands in your notebook\n",
    "* Multiple users can share such clusters to do collaborative interactive analysis\n",
    "* You can terminate, restart, attach, detach these clusters to multiple notebooks\n",
    "* You can choose:\n",
    "    * Multi-Node cluster: Driver and executor nodes will be on seperate machine\n",
    "    * Single Node Cluster: Only there will be a single Driver with single machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82e3a3",
   "metadata": {},
   "source": [
    "### 1.2) Job Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4789c07",
   "metadata": {},
   "source": [
    "* To run the job that you can run as a automated workflows\n",
    "* It runs a new job cluster and terminate the cluster automatically when the job is complete\n",
    "* You cannot restart a job cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1ed6f",
   "metadata": {},
   "source": [
    "## 2) DBUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be35c554",
   "metadata": {},
   "source": [
    "* Databricks provides set of utilities to efficiently interact with your notebook. The most commanly used DBUtils are\n",
    "    * File system Utilities\n",
    "    * Widget Utilities\n",
    "    * Notebook Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301fb6f-e89e-460b-a29d-a9f9594f1fe9",
   "metadata": {},
   "source": [
    "dbutils.widgets.text(name='text_name', defaultvalue='', label='Text Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37dd509-3e62-457d-8be8-d8831adead75",
   "metadata": {},
   "source": [
    "res = dbutils.widgets.get(text_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831e993-524f-4e58-9983-f704601e8bfb",
   "metadata": {},
   "source": [
    "# <font color=Blue>Delta Lake</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c40c5-af18-4f60-9467-0a7c8b619ed8",
   "metadata": {},
   "source": [
    "## Drawbacks of ADLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299e9d2-e2b6-4a36-8158-fcd80c3d3402",
   "metadata": {},
   "source": [
    "1. No ACID properties\n",
    "2. Job failures leads to inconsistent data\n",
    "3. Simultaneous write on same folder brings incorrect results\n",
    "4. No schema enforcement\n",
    "5. No support for updates (update & delete)\n",
    "6. No support for versioning\n",
    "7. Data quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebd47d-7e69-40d9-8a13-fb2a94dc3612",
   "metadata": {},
   "source": [
    "## 1) What is Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243e4fe-b0ec-4955-ad3e-0588e11618a0",
   "metadata": {},
   "source": [
    "* Open source storage framework that brings reliability to data lakes\n",
    "* Brings **transactional** capabilities to data lakes\n",
    "* Runs on top of your existing data lake and support **parquet**\n",
    "* Enables **LakeHouse** architecture\n",
    "* Using **Delta Lake** we can implement LakeHouse architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7236a-7bd9-4ec3-b7e6-6eea954a04cd",
   "metadata": {},
   "source": [
    "abfss://container@storage_account.dfs.core.windows.net/folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496a96e-2056-4502-a296-0b4f90536f9b",
   "metadata": {},
   "source": [
    "### Read CSV from ADLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d43069-6c6b-4577-8945-37cc94bea684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "schema_1 = StructType([StructField(\"emp_name\", StringType()),\n",
    "                       StructField(\"emp_id\", IntegerType()),\n",
    "                       StrcutField(\"gender\", StringType())    \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7e765-e4c0-4bfc-bfb4-67de8c635414",
   "metadata": {},
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "                            .schema(schema_1)\n",
    "                            .load(\"abfss://container@adlsstorage.dfs.core.windows.net/folder/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef9ad9-6232-4256-b6f7-0ed6d92128ce",
   "metadata": {},
   "source": [
    "### Write to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc27e1-a5be-4c5b-9a74-b3f4910c86fa",
   "metadata": {},
   "source": [
    "df.write.format(\"parquet\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(\"abfss://container@storage.dfs.core.windows.net/folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f52b9c-5357-4926-b4a0-f38b00515132",
   "metadata": {},
   "source": [
    "### Reading parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccccf01-d04c-498b-9b9c-ced94df904a2",
   "metadata": {},
   "source": [
    "df_1 = spark.read.format(\"parquet\") \\\n",
    "                .load(\"abfss://container@storage.dfs.core.windows.net/folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19608d3a-7672-4adb-bfbe-841c9969105c",
   "metadata": {},
   "source": [
    "## 2) Create Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def9c6e-763d-43ec-b285-57f1e5544cbb",
   "metadata": {},
   "source": [
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(\"abfss://container@storage.dfs.core.windows.net/folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c5f1e-afe6-49fd-9516-847db0155233",
   "metadata": {},
   "source": [
    "* when we create delta format file, there will be two files\n",
    "* 1) _delta_log folder\n",
    "  2) snappy.parquet file\n",
    " <br>\n",
    "* **_delta_log** folder creates delta lake. It contains\n",
    "* 1.1) _tmp_path_dir folder\n",
    "* 1.2) .crc checksum file\n",
    "* 1.3) .json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9c8c7-e886-449c-9318-70aa9e79eebb",
   "metadata": {},
   "source": [
    "### Reading Delta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ec575-74cb-41ac-9e06-9581cae764ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\") \\\n",
    "                .load(\"abfss://container@storage.dfs.core.windows.net/folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9d709-6d4c-4c3b-b161-93eb79549069",
   "metadata": {},
   "source": [
    "### Create Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59e9fd-a339-40b9-abb1-ee6b307719be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(\"`schema_name`.table_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdfccc-f50d-4b8d-b638-7bad9493ffd7",
   "metadata": {},
   "source": [
    "### Schema Enforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf94cc-f42a-4c2e-b4a3-2739d8da3199",
   "metadata": {},
   "source": [
    "* Delta Lake uses Schema Validation on **Writes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9cda8-339e-4111-85a0-7430a996dc97",
   "metadata": {},
   "source": [
    "#### Schema enforcement Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9aca-b7db-41fb-980a-404c583155cf",
   "metadata": {},
   "source": [
    "* Can't contain any additional columns that are not present in the target table's schema\n",
    "* Can't have different data type from the data type in the target table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03edc1-c0cb-49b3-89ad-2cae0f498597",
   "metadata": {},
   "source": [
    "### Schema Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb1508-e663-4304-9880-a90910a7ce2d",
   "metadata": {},
   "source": [
    "* It allows changes for additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59639c-150a-4c42-b503-7e01564495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(\"`schema_name`.table_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f583ce17-447c-4c3f-a532-73a7ea0d0d2b",
   "metadata": {},
   "source": [
    "* It allows changes for different schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae72f0-bb52-426a-84a6-c2ba2285a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.writ.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(\"`schema_name`.table_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527a13e-74d8-4fc7-9284-8a9c8ac9b09c",
   "metadata": {},
   "source": [
    "### Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9241d66-2606-4ed2-b102-2e599a6b4e4f",
   "metadata": {},
   "source": [
    "### By using **versionAsOf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e0370-7206-4468-ad55-bb337fbe775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\") \\\n",
    "                .option(\"versionAsOf\", \"1\")\n",
    "                .load(\"dbfs:/user/hive/warehouse/db_name.db/table_name/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924e1b0-f90c-4cfe-bc26-2fcfdecd9757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1eb75-0143-4e62-a4fc-d04ff6225bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\") \\\n",
    "                .option(\"timestampAsOf\", \"1\")\n",
    "                .load(\"dbfs:/user/hive/warehouse/db_name.db/table_name/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd6e9d-69d1-4da7-87b8-0a0248b16bfc",
   "metadata": {},
   "source": [
    "# <font color=Blue>Unity Catalog</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758cfc0-0db2-4318-b131-942c3d19008d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
